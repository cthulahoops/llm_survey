<!DOCTYPE html>
<html>
    <head>
        <title>LLM Survey</title>
        {% include "head.html.j2" %}
    </head>
    <body>

        <h1>LLM Survey</h1>

        {% include "github-banner.html.j2" %}
        <main class=contained>

            <p>I gave {{ data|length }} LLM models the same prompt, and evaluated the results with {{ prompt.evaluation_model | model_name }}.  Here's how they did:
</p>


            <table class="highlight-hover">
                <thead>
                <tr>
                    <th>Model</th>
                    <th>Cost (Â¢)</th>
                    <th>Score</th>
                </tr>
                </thead>
                {% for model in models %}
                    <tr>
                        <td>
                            {{ model | model_link }}
                        </td>
                        {% if costs[model] %}
                        <td style="--data-value: {{ 1 - costs[model]|float * (100 / 8) }}">
                        {% else %}
                        <td>
                        {% endif %}
                            {% set cost = costs[model]*100 %}
                            {{ "%.2f"|format(cost) }}
                        </td>
                        {% with scores = outputs.model_scores(model, prompt.evaluation_model) %}
                        {% if scores %}
                        <td title="N={{ scores|length }}" style="--data-value: {{ (scores | average) / 10 }}">
                            {{ "%.1f"|format( scores | average )}}
                        </td>
                        {% else %}
                        <td></td>
                        {% endif %}
                        {% endwith %}
                    </tr>
                {% endfor %}
            </table>

            <p>View full <a href="rankings.html">Detailed Rankings</a>.</p>
            <p>Compare <a href="evaluators.html">different evaluators</a>.</p>
        </main>
    </body>
</html>
